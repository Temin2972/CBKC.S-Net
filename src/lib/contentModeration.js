// Content Moderation using Google AI Studio API (Gemini)

const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY
const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent'

// Debug: Log API key status (remove in production)
console.log('Gemini API Key configured:', GEMINI_API_KEY ? 'Yes (length: ' + GEMINI_API_KEY.length + ')' : 'No')

// Flag levels
export const FLAG_LEVELS = {
  NORMAL: 0,        // No issues detected
  MILD: 1,          // Mild negative language - post allowed but flagged
  IMMEDIATE: 2,     // Suicide/self-harm/depression - needs immediate attention
  BLOCKED: 3,       // Aggressive/violent - auto-blocked
  PENDING: 4        // API unavailable - pending counselor review
}

// Moderation result types
export const MODERATION_ACTIONS = {
  ALLOW: 'allow',           // Content is fine, post normally
  FLAG_MILD: 'flag_mild',   // Post but flag for review
  REJECT: 'reject',         // Don't post, notify counselors, suggest chat
  BLOCK: 'block',           // Don't post, content is aggressive/harmful
  PENDING: 'pending'        // API down - hold for counselor review
}

const MODERATION_PROMPT = `You are a content moderation AI for a mental health support platform for students. Analyze the following content and categorize it.

IMPORTANT: Respond ONLY with a valid JSON object, no other text.

Categories:
1. "safe" - Normal content, no concerns
2. "mild_negative" - Mild negative emotions, sadness, stress, frustration (but not dangerous)
3. "severe_distress" - Severe emotional distress, hopelessness, but no explicit self-harm
4. "depression" - Clear signs of depression, persistent sadness, loss of interest
5. "self_harm" - Mentions of self-harm, cutting, hurting oneself
6. "suicide" - Suicidal ideation, thoughts of ending life, wanting to die
7. "aggressive" - Violent intentions, threats, bullying, hate speech, harmful to others

Response format:
{
  "category": "one of the categories above",
  "confidence": 0.0 to 1.0,
  "reasoning": "brief explanation in Vietnamese",
  "keywords_detected": ["list", "of", "concerning", "words"]
}

Content to analyze:
"""
{CONTENT}
"""

Remember: Only output the JSON object, nothing else.`

/**
 * Analyze content using Google AI Studio (Gemini)
 * @param {string} content - The text content to analyze
 * @returns {Promise<{action: string, flagLevel: number, category: string, reasoning: string, keywords: string[]}>}
 */
export async function analyzeContent(content) {
  // Result when API fails - content goes to pending review
  const pendingResult = {
    action: MODERATION_ACTIONS.PENDING,
    flagLevel: FLAG_LEVELS.PENDING,
    category: 'pending',
    reasoning: 'API unavailable - pending counselor review',
    keywords: []
  }

  if (!GEMINI_API_KEY) {
    console.warn('‚ùå Gemini API key not configured!')
    console.warn('Make sure VITE_GEMINI_API_KEY is set in your .env file')
    return pendingResult
  }

  if (!content || content.trim().length === 0) {
    return {
      action: MODERATION_ACTIONS.ALLOW,
      flagLevel: FLAG_LEVELS.NORMAL,
      category: 'safe',
      reasoning: 'Empty content',
      keywords: []
    }
  }

  try {
    console.log('üîç Analyzing content with Gemini API...')
    const prompt = MODERATION_PROMPT.replace('{CONTENT}', content)

    const response = await fetch(`${GEMINI_API_URL}?key=${GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        contents: [{
          parts: [{ text: prompt }]
        }],
        generationConfig: {
          temperature: 0.1,
          maxOutputTokens: 500
        }
      })
    })

    console.log('üì° API Response status:', response.status)

    if (!response.ok) {
      const errorText = await response.text()
      console.error('‚ùå Gemini API error:', response.status, errorText)
      return pendingResult
    }

    const data = await response.json()
    console.log('‚úÖ API Response received:', data)
    
    // Extract the text response
    const textResponse = data.candidates?.[0]?.content?.parts?.[0]?.text
    
    if (!textResponse) {
      console.error('‚ùå No text in API response')
      return pendingResult
    }

    // Parse JSON from response
    const jsonMatch = textResponse.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      console.error('‚ùå Could not parse JSON from response:', textResponse)
      return pendingResult
    }

    const analysis = JSON.parse(jsonMatch[0])
    console.log('‚úÖ Content analysis result:', analysis)
    
    // Map category to action and flag level
    return mapCategoryToAction(analysis)

  } catch (error) {
    console.error('‚ùå Content moderation error:', error)
    return pendingResult
  }
}

/**
 * Map the AI analysis category to moderation action and flag level
 */
function mapCategoryToAction(analysis) {
  const { category, confidence, reasoning, keywords_detected } = analysis
  
  const result = {
    category,
    reasoning: reasoning || '',
    keywords: keywords_detected || [],
    confidence: confidence || 0
  }

  switch (category) {
    case 'safe':
      return {
        ...result,
        action: MODERATION_ACTIONS.ALLOW,
        flagLevel: FLAG_LEVELS.NORMAL
      }

    case 'mild_negative':
    case 'severe_distress':
      // Mild concerns - post but flag for counselor review
      return {
        ...result,
        action: MODERATION_ACTIONS.FLAG_MILD,
        flagLevel: FLAG_LEVELS.MILD
      }

    case 'depression':
    case 'self_harm':
    case 'suicide':
      // Immediate attention needed - reject post, notify counselors
      return {
        ...result,
        action: MODERATION_ACTIONS.REJECT,
        flagLevel: FLAG_LEVELS.IMMEDIATE
      }

    case 'aggressive':
      // Block aggressive content
      return {
        ...result,
        action: MODERATION_ACTIONS.BLOCK,
        flagLevel: FLAG_LEVELS.BLOCKED
      }

    default:
      // Unknown category, default to allow
      return {
        ...result,
        action: MODERATION_ACTIONS.ALLOW,
        flagLevel: FLAG_LEVELS.NORMAL
      }
  }
}

/**
 * Get Vietnamese message for moderation result
 */
export function getModerationMessage(action, category) {
  switch (action) {
    case MODERATION_ACTIONS.BLOCK:
      return {
        title: 'N·ªôi dung kh√¥ng ƒë∆∞·ª£c ph√©p',
        message: 'B√†i vi·∫øt c·ªßa b·∫°n ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p v√† kh√¥ng th·ªÉ ƒë∆∞·ª£c ƒëƒÉng.',
        showChatSuggestion: false
      }

    case MODERATION_ACTIONS.REJECT:
      return {
        title: 'Ch√∫ng t√¥i quan t√¢m ƒë·∫øn b·∫°n',
        message: 'Ch√∫ng t√¥i nh·∫≠n th·∫•y b·∫°n c√≥ th·ªÉ ƒëang tr·∫£i qua giai ƒëo·∫°n kh√≥ khƒÉn. B√†i vi·∫øt n√†y kh√¥ng th·ªÉ ƒë∆∞·ª£c ƒëƒÉng c√¥ng khai, nh∆∞ng ch√∫ng t√¥i khuy·∫øn kh√≠ch b·∫°n tr√≤ chuy·ªán tr·ª±c ti·∫øp v·ªõi t∆∞ v·∫•n vi√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ t·ªët h∆°n.',
        showChatSuggestion: true
      }

    case MODERATION_ACTIONS.PENDING:
      return {
        title: 'ƒêang ch·ªù duy·ªát',
        message: 'B√†i vi·∫øt c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c g·ª≠i v√† ƒëang ch·ªù t∆∞ v·∫•n vi√™n xem x√©t. B·∫°n s·∫Ω ƒë∆∞·ª£c th√¥ng b√°o khi b√†i vi·∫øt ƒë∆∞·ª£c duy·ªát.',
        showChatSuggestion: false
      }

    case MODERATION_ACTIONS.FLAG_MILD:
      return {
        title: 'ƒê√£ ƒëƒÉng b√†i',
        message: 'B√†i vi·∫øt c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c ƒëƒÉng. N·∫øu b·∫°n c·∫ßn h·ªó tr·ª£, ƒë·ª´ng ng·∫ßn ng·∫°i li√™n h·ªá v·ªõi t∆∞ v·∫•n vi√™n.',
        showChatSuggestion: false
      }

    default:
      return {
        title: 'ƒê√£ ƒëƒÉng b√†i',
        message: 'B√†i vi·∫øt c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c ƒëƒÉng th√†nh c√¥ng.',
        showChatSuggestion: false
      }
  }
}

/**
 * Get flag level label in Vietnamese
 */
export function getFlagLevelLabel(level) {
  switch (level) {
    case FLAG_LEVELS.IMMEDIATE:
      return 'C·∫ßn ch√∫ √Ω ngay'
    case FLAG_LEVELS.MILD:
      return 'Theo d√µi'
    case FLAG_LEVELS.BLOCKED:
      return 'ƒê√£ ch·∫∑n'
    case FLAG_LEVELS.PENDING:
      return 'Ch·ªù duy·ªát'
    default:
      return 'B√¨nh th∆∞·ªùng'
  }
}

/**
 * Get category label in Vietnamese
 */
export function getCategoryLabel(category) {
  const labels = {
    'safe': 'An to√†n',
    'mild_negative': 'Ti√™u c·ª±c nh·∫π',
    'severe_distress': 'CƒÉng th·∫≥ng nghi√™m tr·ªçng',
    'depression': 'Tr·∫ßm c·∫£m',
    'self_harm': 'T·ª± g√¢y th∆∞∆°ng t√≠ch',
    'suicide': '√ù ƒë·ªãnh t·ª± t·ª≠',
    'aggressive': 'Hung hƒÉng/B·∫°o l·ª±c'
  }
  return labels[category] || category
}
